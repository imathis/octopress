<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ruby | Avi Tzurel]]></title>
  <link href="http://avi.io/blog/categories/ruby/atom.xml" rel="self"/>
  <link href="http://avi.io/"/>
  <updated>2013-10-06T16:17:55+03:00</updated>
  <id>http://avi.io/</id>
  <author>
    <name><![CDATA[Avi Tzurel]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Move jobs from one queue to another - Sidekiq]]></title>
    <link href="http://avi.io/blog/2013/08/14/move-jobs-from-one-queue-to-another-sidekiq/"/>
    <updated>2013-08-14T17:36:00+03:00</updated>
    <id>http://avi.io/blog/2013/08/14/move-jobs-from-one-queue-to-another-sidekiq</id>
    <content type="html"><![CDATA[<p>I have been working with Sidekiq for quite a while now, having many jobs per day working (multiple millions of jobs.)</p>

<p>Sometimes, I queue up tasks to a queue called <code>#{queue_name}_pending</code>, I do this so I can manage the load on the servers. (For example: Stop writing to Mongo, Stop importing contact etc...)</p>

<p>This way, I can queue up many jobs, and I can move it to the real queue whenever I feel like it or whenever the problem is solved.</p>

<p>I was looking for a way to move tasks from one queue to another.</p>

<p>There's nothing built into Sidekiq for this, but obviously, you can just use redis built in commands to do it.</p>

<p>Here's the code to do it</p>

<p>```ruby</p>

<pre><code>count_block = proc{ Sidekiq.redis do |conn|
  conn.llen("queue:#{queue_name}")  
end }

while count_block.call &gt; 0
  Sidekiq.redis do |conn|
    conn.rpoplpush "queue:#{queue_name}_pending", "queue:#{queue_name}"
  end
end
</code></pre>

<p>```</p>

<p>This will move all the items from one queue to another until there are no more jobs.</p>

<p>b.t.w
Obviously, the <code>_pending</code> queues don't have any workers assigned to them, the purpose of it is a place holder so the jobs won't go to waste and we can resume work when we can.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DO NOT use the callbacks that require persistence in Mongoid]]></title>
    <link href="http://avi.io/blog/2013/02/19/do-not-use-the-callbacks-that-require-persistence-in-mongoid/"/>
    <updated>2013-02-19T22:10:00+02:00</updated>
    <id>http://avi.io/blog/2013/02/19/do-not-use-the-callbacks-that-require-persistence-in-mongoid</id>
    <content type="html"><![CDATA[<p>I started using MongoDB at <a href="http://www.gogobot.com">Gogobot</a> a little while ago.
While using it, I encountered some <a href="http://avi.io/blog/2013/01/30/problems-with-mongoid-and-sidekiq-brainstorming/">problems</a>, but for the most part, things went pretty smooth.</p>

<p>Today, I encountered a bug that surprised me.</p>

<p>While it certainly should not have, I think it can surprise you as well, so I am writing it up here as a fair warning.</p>

<p>For Gogobot, the entire graph is built on top of MongoDB, all the things social are driven by it and for the most parts like I mentioned, we are pretty happy with it.</p>

<h2>SO, What was the problem?</h2>

<p>The entire graph is a mountable engine, we can decide to turn it on or to turn it off at will.
It acts as a data warehouse and the workflows are being managed by the app.</p>

<p>For example:</p>

<p>When model X is created, app is notified and decides what to do with this notification, and so on and so forth.</p>

<p>Everything peachy so far, nothing we haven't used hundreds of times in the past.</p>

<p>Here's how it works.</p>

<p>We have a model called <code>VisitedPlace</code>, it's a representation of a user that visited a certain place</p>

<p>Here's the code</p>

<p>```ruby</p>

<pre><code>module GraphEngine
  class FbPlace
    include Mongoid::Document
    include Mongoid::Timestamps
    include GraphEngine::Notifications::NotifiableModel

    #… rest of code here
  end
end
</code></pre>

<p>```</p>

<p>As you can see, this model includes a module called <code>NotifiableModel</code>, here's the important part from it:</p>

<p>```ruby</p>

<pre><code>module GraphEngine
  module Notifications
    module NotifiableModel
      extend ActiveSupport::Concern

      included do
        after_create do
          send_notification("created")
        end
      end

      def send_notification(verb)
        # Notify the app here...
      end
    end
  end
end
</code></pre>

<p>```</p>

<p>Like I said, pretty standard stuff, nothing too fancy, but here's where it's getting tricky.</p>

<p>This model has a unique index on <code>user_id</code> and <code>place_id</code>. It's a unique index and no two documents can exist in the same collection.</p>

<p>BUT… check this out:</p>

<p><code>ruby
  GraphEngine::VisitedPlace.create!(user_id: 1, place_id: 1) =&gt; true
  GraphEngine::VisitedPlace.create!(user_id: 1, place_id: 1) =&gt; true
</code></p>

<p>The second query actually failed in the DB level, but the application still returned true.</p>

<p>Meaning, that <code>after_create</code> is actually being called even if the record is <strong>not really persisted</strong>.</p>

<h2>How you can fix? / should you fix?</h2>

<p>For Gogobot, I fixed it using safe mode on those models, I don't mind the performance penalty, since I don't want to trigger Sidekiq workers that will do all sorts of things twice or three times.</p>

<p>Should you do the same? I am not sure, you need to benchmark your app and see if you can fix it in another way.</p>

<p>Would love to hear back from you in comments/discussion</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Problems with Mongoid and Sidekiq- Brainstorming]]></title>
    <link href="http://avi.io/blog/2013/01/30/problems-with-mongoid-and-sidekiq-brainstorming/"/>
    <updated>2013-01-30T20:13:00+02:00</updated>
    <id>http://avi.io/blog/2013/01/30/problems-with-mongoid-and-sidekiq-brainstorming</id>
    <content type="html"><![CDATA[<p>A few weeks back, we started slowly upgrading all of our queues at <a href="http://www.gogobot.com">Gogobot</a> to work with <a href="https://github.com/mperham/sidekiq">Sidekiq</a>.</p>

<p>Posts on how awesome the experience was and how much better Sidekiq is from <a href="http://github.com/defunkt/sidekiq">Resque</a> coming soon, though with all the good came some bad.</p>

<h2>Summary of the solution</h2>

<p>With Sidekiq, we are processing around <strong>25X more</strong> jobs than what we were doing with Resque, processing around 15,000,000 jobs per day, at paces of over 1K per second at times (at peak we go up well past that)</p>

<p>This is how many jobs we processed today…</p>

<p><img src="http://d.pr/i/O9aU+" alt="Sidekiq history graph for today" /></p>

<p>And this is a snapshot of our realtime graph</p>

<p><img src="http://d.pr/i/7Fkr+" alt="Realtime graph snapshot" /></p>

<p>On the MongoDB side we are working with Mongoid and we have a shared environment, 9 shards with 3 replicas in each shard, all running through 2 routers.</p>

<p>Our production mongoid config looks like this</p>

<p>```yaml
production:
  op_timeout: 3
  connection_timeout: 3
  sessions:</p>

<pre><code>default:
  hosts:
    - HOST_NAME:27017 #Single router R0
  username: USER_NAME
  password: PASSWORD
  database: DATABASE_NAME
  options:
    consistency: :eventual
</code></pre>

<p>```</p>

<p>We are using latest versions of all relevant gems (Sidekiq, Mongoid, Moped, Redis)</p>

<h2>All seems fine right? What's the problem?</h2>

<p>The problem is that we have too many connections opening and closing to our mongo instances. (~25-40 new connections per second).</p>

<p>Each time a job is picked up, a connection to Mongo is opened and when the job is done, this connection is closed (using Kiqstand middleware).</p>

<p>This is causing huge loads on our router server, and causing mongo to run out of file descriptors at times.</p>

<h2>SO?</h2>

<p>More then anything, this post is a callout for discussion with anyone using similar solution with similar scale and can assist, I know I would love to brainstorm on how to solve this problem.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[organizing your specs into groups and running them separately]]></title>
    <link href="http://avi.io/blog/2012/08/19/organizing-your-specs-into-groups-and-running-them-separately/"/>
    <updated>2012-08-19T13:57:00+03:00</updated>
    <id>http://avi.io/blog/2012/08/19/organizing-your-specs-into-groups-and-running-them-separately</id>
    <content type="html"><![CDATA[<p>A while back I answered <a href="http://stackoverflow.com/questions/10029250/organizing-rspec-2-tests-into-unit-and-integration-categories-in-rails/10029504#10029504">this StackOverflow question</a>.</p>

<p>When you have a lot of specs, it makes sense to run them in separate logical groups and not just with <code>rspec spec</code> or something like that.</p>

<p>This way, you can save time and you can also run them in separate processes on the CI.</p>

<p>For example:</p>

<p><code>
bundle exec rake spec:unit
bundle exec rake spec:integration
bundle exec rake spec:api
</code></p>

<p>In order to achieve this, you need to change the <code>spec.rake</code> file.</p>

<p>```ruby
  namespace :spec do</p>

<pre><code>Rspec::Core::RakeTask.new(:unit) do |t|
  t.pattern = Dir['spec/*/**/*_spec.rb'].reject{ |f| f['/api/v1'] || f['/integration'] }
end
</code></pre>

<p>   Rspec::Core::RakeTask.new(:api) do |t|</p>

<pre><code>  t.pattern = "spec/*/{api/v1}*/**/*_spec.rb"
end

Rspec::Core::RakeTask.new(:integration) do |t|
  t.pattern = "spec/integration/**/*_spec.rb"
end
</code></pre>

<p>  end
```
You can continue customizing that all you want, you can run specific specs that are the most important to you.</p>

<p>I find those groups useful for most of my use cases, but with minor changes you can make it fit yours</p>

<h3>Using Rspec Tags</h3>

<p>You can use tags for that as well, but I find that more tedious and you can forget to <em>tag</em> something.</p>

<p>For example:</p>

<p><code>ruby
  it "should do some integration test", :integration =&gt; true do
   # something
  end
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Making Nokogiri install again on Mountain Lion]]></title>
    <link href="http://avi.io/blog/2012/08/09/making-nokogiri-install-again-on-mountain-lion/"/>
    <updated>2012-08-09T00:04:00+03:00</updated>
    <id>http://avi.io/blog/2012/08/09/making-nokogiri-install-again-on-mountain-lion</id>
    <content type="html"><![CDATA[<p>As probably any geek out there, I upgraded my OS to Apple Mountain Lion.</p>

<p>The upgrade created a lot of problems for me, I basically had to reinstall almost everything, from MySql to homebrew.</p>

<p>I am not sure if everyone experienced the same thing, but that was the case for me.</p>

<p>One of the problems I encountered was that I could not install Nokogiri anymore on my machine, bundler would not install it and complain about dependencies not being installed (specifically <code>libxml</code>)</p>

<p>To fix it, you need to reinstall Ruby using RVM with livxml properly linked.</p>

<p>First, install <code>libxml</code> and <code>libxslt</code> through homebrew, like so:</p>

<p><code>
brew install libxml2 libxslt
brew link libxml2 libxslt
</code></p>

<p>If that doesn't work you probably need to install <code>libiconv</code> like so:</p>

<p><code>
cd  
mkdir temp
cd temp
ls
wget http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.13.1.tar.gz
tar xvfz libiconv-1.13.1.tar.gz
cd libiconv-1.13.1
./configure --prefix=/usr/local/Cellar/libiconv/1.13.1
make
sudo make install
</code></p>

<p>And then install <code>libxml</code> and <code>libxslt</code> again</p>

<p><code>
brew install libxml2 libxslt
brew link libxml2 libxslt
</code></p>

<p>Once that's done without errors, reinstall Ruby.</p>

<p><code>
rvm reinstall ruby-1.9.3-p194
</code></p>

<p>RVM will figure out those libraries location and properly install Ruby with those linked up.</p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
</feed>
