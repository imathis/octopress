<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ruby | Avi Tzurel]]></title>
  <link href="http://avi.io/blog/categories/ruby/atom.xml" rel="self"/>
  <link href="http://avi.io/"/>
  <updated>2013-03-01T20:40:39+02:00</updated>
  <id>http://avi.io/</id>
  <author>
    <name><![CDATA[Avi Tzurel]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[DO NOT use the callbacks that require persistence in Mongoid]]></title>
    <link href="http://avi.io/blog/2013/02/19/do-not-use-the-callbacks-that-require-persistence-in-mongoid/"/>
    <updated>2013-02-19T22:10:00+02:00</updated>
    <id>http://avi.io/blog/2013/02/19/do-not-use-the-callbacks-that-require-persistence-in-mongoid</id>
    <content type="html"><![CDATA[<p>I started using MongoDB at <a href="http://www.gogobot.com">Gogobot</a> a little while ago.
While using it, I encountered some <a href="http://avi.io/blog/2013/01/30/problems-with-mongoid-and-sidekiq-brainstorming/">problems</a>, but for the most part, things went pretty smooth.</p>

<p>Today, I encountered a bug that surprised me.</p>

<p>While it certainly should not have, I think it can surprise you as well, so I am writing it up here as a fair warning.</p>

<p>For Gogobot, the entire graph is built on top of MongoDB, all the things social are driven by it and for the most parts like I mentioned, we are pretty happy with it.</p>

<h2>SO, What was the problem?</h2>

<p>The entire graph is a mountable engine, we can decide to turn it on or to turn it off at will.
It acts as a data warehouse and the workflows are being managed by the app.</p>

<p>For example:</p>

<p>When model X is created, app is notified and decides what to do with this notification, and so on and so forth.</p>

<p>Everything peachy so far, nothing we haven't used hundreds of times in the past.</p>

<p>Here's how it works.</p>

<p>We have a model called <code>VisitedPlace</code>, it's a representation of a user that visited a certain place</p>

<p>Here's the code</p>

<p>```ruby</p>

<pre><code>module GraphEngine
  class FbPlace
    include Mongoid::Document
    include Mongoid::Timestamps
    include GraphEngine::Notifications::NotifiableModel

    #… rest of code here
  end
end
</code></pre>

<p>```</p>

<p>As you can see, this model includes a module called <code>NotifiableModel</code>, here's the important part from it:</p>

<p>```ruby</p>

<pre><code>module GraphEngine
  module Notifications
    module NotifiableModel
      extend ActiveSupport::Concern

      included do
        after_create do
          send_notification("created")
        end
      end

      def send_notification(verb)
        # Notify the app here...
      end
    end
  end
end
</code></pre>

<p>```</p>

<p>Like I said, pretty standard stuff, nothing too fancy, but here's where it's getting tricky.</p>

<p>This model has a unique index on <code>user_id</code> and <code>place_id</code>. It's a unique index and no two documents can exist in the same collection.</p>

<p>BUT… check this out:</p>

<p><code>ruby
  GraphEngine::VisitedPlace.create!(user_id: 1, place_id: 1) =&gt; true
  GraphEngine::VisitedPlace.create!(user_id: 1, place_id: 1) =&gt; true
</code></p>

<p>The second query actually failed in the DB level, but the application still returned true.</p>

<p>Meaning, that <code>after_create</code> is actually being called even if the record is <strong>not really persisted</strong>.</p>

<h2>How you can fix? / should you fix?</h2>

<p>For Gogobot, I fixed it using safe mode on those models, I don't mind the performance penalty, since I don't want to trigger Sidekiq workers that will do all sorts of things twice or three times.</p>

<p>Should you do the same? I am not sure, you need to benchmark your app and see if you can fix it in another way.</p>

<p>Would love to hear back from you in comments/discussion</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Problems with Mongoid and Sidekiq- Brainstorming]]></title>
    <link href="http://avi.io/blog/2013/01/30/problems-with-mongoid-and-sidekiq-brainstorming/"/>
    <updated>2013-01-30T20:13:00+02:00</updated>
    <id>http://avi.io/blog/2013/01/30/problems-with-mongoid-and-sidekiq-brainstorming</id>
    <content type="html"><![CDATA[<p>A few weeks back, we started slowly upgrading all of our queues at <a href="http://www.gogobot.com">Gogobot</a> to work with <a href="https://github.com/mperham/sidekiq">Sidekiq</a>.</p>

<p>Posts on how awesome the experience was and how much better Sidekiq is from <a href="http://github.com/defunkt/sidekiq">Resque</a> coming soon, though with all the good came some bad.</p>

<h2>Summary of the solution</h2>

<p>With Sidekiq, we are processing around <strong>25X more</strong> jobs than what we were doing with Resque, processing around 15,000,000 jobs per day, at paces of over 1K per second at times (at peak we go up well past that)</p>

<p>This is how many jobs we processed today…</p>

<p><img src="http://d.pr/i/O9aU+" alt="Sidekiq history graph for today" /></p>

<p>And this is a snapshot of our realtime graph</p>

<p><img src="http://d.pr/i/7Fkr+" alt="Realtime graph snapshot" /></p>

<p>On the MongoDB side we are working with Mongoid and we have a shared environment, 9 shards with 3 replicas in each shard, all running through 2 routers.</p>

<p>Our production mongoid config looks like this</p>

<p>```yaml
production:
  op_timeout: 3
  connection_timeout: 3
  sessions:</p>

<pre><code>default:
  hosts:
    - HOST_NAME:27017 #Single router R0
  username: USER_NAME
  password: PASSWORD
  database: DATABASE_NAME
  options:
    consistency: :eventual
</code></pre>

<p>```</p>

<p>We are using latest versions of all relevant gems (Sidekiq, Mongoid, Moped, Redis)</p>

<h2>All seems fine right? What's the problem?</h2>

<p>The problem is that we have too many connections opening and closing to our mongo instances. (~25-40 new connections per second).</p>

<p>Each time a job is picked up, a connection to Mongo is opened and when the job is done, this connection is closed (using Kiqstand middleware).</p>

<p>This is causing huge loads on our router server, and causing mongo to run out of file descriptors at times.</p>

<h2>SO?</h2>

<p>More then anything, this post is a callout for discussion with anyone using similar solution with similar scale and can assist, I know I would love to brainstorm on how to solve this problem.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[organizing your specs into groups and running them separately]]></title>
    <link href="http://avi.io/blog/2012/08/19/organizing-your-specs-into-groups-and-running-them-separately/"/>
    <updated>2012-08-19T13:57:00+03:00</updated>
    <id>http://avi.io/blog/2012/08/19/organizing-your-specs-into-groups-and-running-them-separately</id>
    <content type="html"><![CDATA[<p>A while back I answered <a href="http://stackoverflow.com/questions/10029250/organizing-rspec-2-tests-into-unit-and-integration-categories-in-rails/10029504#10029504">this StackOverflow question</a>.</p>

<p>When you have a lot of specs, it makes sense to run them in separate logical groups and not just with <code>rspec spec</code> or something like that.</p>

<p>This way, you can save time and you can also run them in separate processes on the CI.</p>

<p>For example:</p>

<p><code>
bundle exec rake spec:unit
bundle exec rake spec:integration
bundle exec rake spec:api
</code></p>

<p>In order to achieve this, you need to change the <code>spec.rake</code> file.</p>

<p>```ruby
  namespace :spec do</p>

<pre><code>Rspec::Core::RakeTask.new(:unit) do |t|
  t.pattern = Dir['spec/*/**/*_spec.rb'].reject{ |f| f['/api/v1'] || f['/integration'] }
end
</code></pre>

<p>   Rspec::Core::RakeTask.new(:api) do |t|</p>

<pre><code>  t.pattern = "spec/*/{api/v1}*/**/*_spec.rb"
end

Rspec::Core::RakeTask.new(:integration) do |t|
  t.pattern = "spec/integration/**/*_spec.rb"
end
</code></pre>

<p>  end
```
You can continue customizing that all you want, you can run specific specs that are the most important to you.</p>

<p>I find those groups useful for most of my use cases, but with minor changes you can make it fit yours</p>

<h3>Using Rspec Tags</h3>

<p>You can use tags for that as well, but I find that more tedious and you can forget to <em>tag</em> something.</p>

<p>For example:</p>

<p><code>ruby
  it "should do some integration test", :integration =&gt; true do
   # something
  end
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Making Nokogiri install again on Mountain Lion]]></title>
    <link href="http://avi.io/blog/2012/08/09/making-nokogiri-install-again-on-mountain-lion/"/>
    <updated>2012-08-09T00:04:00+03:00</updated>
    <id>http://avi.io/blog/2012/08/09/making-nokogiri-install-again-on-mountain-lion</id>
    <content type="html"><![CDATA[<p>As probably any geek out there, I upgraded my OS to Apple Mountain Lion.</p>

<p>The upgrade created a lot of problems for me, I basically had to reinstall almost everything, from MySql to homebrew.</p>

<p>I am not sure if everyone experienced the same thing, but that was the case for me.</p>

<p>One of the problems I encountered was that I could not install Nokogiri anymore on my machine, bundler would not install it and complain about dependencies not being installed (specifically <code>libxml</code>)</p>

<p>To fix it, you need to reinstall Ruby using RVM with livxml properly linked.</p>

<p>First, install <code>libxml</code> and <code>libxslt</code> through homebrew, like so:</p>

<p><code>
brew install libxml2 libxslt
brew link libxml2 libxslt
</code></p>

<p>If that doesn't work you probably need to install <code>libiconv</code> like so:</p>

<p><code>
cd  
mkdir temp
cd temp
ls
wget http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.13.1.tar.gz
tar xvfz libiconv-1.13.1.tar.gz
cd libiconv-1.13.1
./configure --prefix=/usr/local/Cellar/libiconv/1.13.1
make
sudo make install
</code></p>

<p>And then install <code>libxml</code> and <code>libxslt</code> again</p>

<p><code>
brew install libxml2 libxslt
brew link libxml2 libxslt
</code></p>

<p>Once that's done without errors, reinstall Ruby.</p>

<p><code>
rvm reinstall ruby-1.9.3-p194
</code></p>

<p>RVM will figure out those libraries location and properly install Ruby with those linked up.</p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Creating self starting worker machines for fun and profit]]></title>
    <link href="http://avi.io/blog/2012/08/08/creating-self-starting-worker-machines-for-fun-and-profit/"/>
    <updated>2012-08-08T13:49:00+03:00</updated>
    <id>http://avi.io/blog/2012/08/08/creating-self-starting-worker-machines-for-fun-and-profit</id>
    <content type="html"><![CDATA[<p>Lately, I needed to create worker machines (Machines that have Resque workers on them).</p>

<p>Usually, the process is very manual and tedious, you need to deploy the code to each machine (on code change), you need to start/stop/restart the workers and more.</p>

<p>Since I needed A LOT of workers, I really wanted to make the process automatic.</p>

<p>I wanted the machine to be in charge of everything it needs.</p>

<p>Meaning</p>

<ul>
<li>Pull latest git code</li>
<li>Copy file to the <code>current</code> directory</li>
<li>Startup god (which will start the Resque processes)</li>
</ul>


<p>I wanted the machine to be in charge of all this when it boots up, so in case I need to update the code or something, all I need is to reboot the machines and that's it.</p>

<p>Also, scaling up the process is super easy, all I need is to add more machines.</p>

<p>The logic behind it was also being able to use spot-instances on Amazon, which are much cheaper.</p>

<p>So, as always, I thought I would document the process and open source it.</p>

<h2>Challenges</h2>

<p>What are the challenges we are looking at, when we want to do something like that.</p>

<ol>
<li>Awareness of RVM, Ruby version</li>
<li>Awareness of Bundler and Gem versions.</li>
</ol>


<p>Those are things we need to consider.</p>

<h2>Breaking down the process into pseudo code.</h2>

<p>So, let's break down the process into pseudo code</p>

<p><code>
Go to the temp folder
git pull from origin + branch you want
Copy all files from temp folder to current folder
Go To current folder, bundle install
Start God
</code></p>

<h2>RVM Wrappers</h2>

<p>For the last 2 parts of the process, if you try to do just <code>bundle install --deployment</code> for example, the script will fail, it does not know what bundle is, it resolves to the default Ruby installed on the machine at this point.</p>

<p>Since want the last 2 processes to go through RVM, we need to create a wrapper script.</p>

<h3>Creating RVM Wrappers</h3>

<p>You can create RVM wrappers like this:</p>

<p><code>
rvm wrapper {ruby_version@gemset} {prefix} {executable}
</code></p>

<p>For example</p>

<p><code>
rvm wrapper 1.9.2 bootup god
</code></p>

<p>This will generate this file: (called <code>bootup_god</code>)</p>

<p>```bash</p>

<h1>!/usr/bin/env bash</h1>

<p>if [[ -s "/usr/local/rvm/environments/ruby-1.9.2-p290" ]]
then
  source "/usr/local/rvm/environments/ruby-1.9.2-p290"
  exec god "$@"
else
  echo "ERROR: Missing RVM environment file: '/usr/local/rvm/environments/ruby-1.9.2-p290'" >&amp;2
  exit 1
fi
```</p>

<p>I did the same for bundle which generated this file: (called <code>bootup_bundle</code>)</p>

<p>```bash</p>

<h1>!/usr/bin/env bash</h1>

<p>if [[ -s "/usr/local/rvm/environments/ruby-1.9.2-p290" ]]
then
  source "/usr/local/rvm/environments/ruby-1.9.2-p290"
  exec bundle "$@"
else
  echo "ERROR: Missing RVM environment file: '/usr/local/rvm/environments/ruby-1.9.2-p290'" >&amp;2
  exit 1
fi
```</p>

<p>The files are created in <code>vim /usr/local/rvm/bin/</code>.</p>

<p>Now that we have the wrappers, we made sure the boot up process will be aware of RVM and we can continue.</p>

<h2>RC files</h2>

<p>If you want something to run when the machine starts you need to get to know the <code>rc</code> files.</p>

<p>Usually, those files are located in <code>/etc/</code> folder (may vary of course)</p>

<p>The files are loaded and executed in a specific order</p>

<p><code>
rc
rc{numer}
rc.local
</code></p>

<p>If you want something to run when ALL the rest of the machine bootup process ran, you put it at the end of the rc.local file.</p>

<p>One gotcha here is that the file <em>must</em> end with <code>exit 0</code>, or your script will not run at all, and good luck finding out why :P</p>

<p>I put this line at the end, right before the <code>exit 0</code></p>

<p><code>
sh /root/start_workers.sh
</code></p>

<h2>Finalize</h2>

<p>Now that I have the wrappers, I have the line in rc.local I can finalize the process with creating the shell script.</p>

<p>This is what the script looks for me</p>

<p><code>bash
cd {temp_folder}
git pull origin {branch_name}
cd ..
cp -apRv {source_folder}/* {destination_folder} --reply=yes
echo "Running bundle install"
cd /root/c &amp;&amp; /usr/local/rvm/bin/bootup_bundle install --path /mnt/data-store/html/gogobot/shared/bundle --deployment --without development test
echo "Starting RVM"
/usr/local/rvm/bin/bootup_god -c /root/c/god/resque_extra_workers.god
</code></p>

<p>The god file to start the workers is standard.</p>

<p>```ruby
rails_env   = ENV['RAILS_ENV']  || "production"
rails_root  = ENV['RAILS_ROOT'] || "/mnt/data-store/html/gogobot/current"
WORKER_TIMEOUT = 60 * 10 # 10 minutes</p>

<h1>Stale workers</h1>

<p>Thread.new do
  loop do</p>

<pre><code>begin
  `ps -e -o pid,command | grep [r]esque`.split("\n").each do |line|
    parts   = line.split(' ')
    next if parts[-2] != "at"
    started = parts[-1].to_i
    elapsed = Time.now - Time.at(started)

    if elapsed &gt;= WORKER_TIMEOUT
      ::Process.kill('USR1', parts[0].to_i)
    end
  end
rescue
  # don't die because of stupid exceptions
  nil
end
sleep 30
</code></pre>

<p>  end
end</p>

<p>queue_name = "graph_checkins_import"
num_workers = 10</p>

<h1>FB wall posts</h1>

<p>num_workers.times do |num|
  God.watch do |w|</p>

<pre><code>w.dir      = "#{rails_root}"
w.name     = "resque-#{num}-#{queue_name}"
w.group    = "resque"
w.interval = 2.minutes
w.env      = {"QUEUE"=&gt;"#{queue_name}", "RAILS_ENV"=&gt;rails_env, "PIDFILE" =&gt; "#{rails_root}/tmp/resque_#{queue_name}_#{w}.pid"}
w.pid_file = "#{rails_root}/tmp/resque_#{queue_name}_#{w}.pid"
w.start    = "cd #{rails_root}/ &amp;&amp; bundle exec rake environment resque:work QUEUE=#{queue_name} RAILS_ENV=#{rails_env}"
w.log      = "#{rails_root}/log/resque_god.log"

w.uid = 'root'
w.gid = 'root'

# restart if memory gets too high
w.transition(:up, :restart) do |on|
  on.condition(:memory_usage) do |c|
    c.above = 350.megabytes
    c.times = 2
  end
end

# determine the state on startup
w.transition(:init, { true =&gt; :up, false =&gt; :start }) do |on|
  on.condition(:process_running) do |c|
    c.running = true
  end
end

# determine when process has finished starting
w.transition([:start, :restart], :up) do |on|
  on.condition(:process_running) do |c|
    c.running = true
    c.interval = 5.seconds
  end

  # failsafe
  on.condition(:tries) do |c|
    c.times = 5
    c.transition = :start
    c.interval = 5.seconds
  end
end

# start if process is not running
w.transition(:up, :start) do |on|
  on.condition(:process_running) do |c|
    c.running = false
  end
end
</code></pre>

<p>  end
end
```</p>

<h2>Profit</h2>

<p>Now, it's a completely automatic process, all you need is to run as many machines as you need, once the machine is booted up, it will deploy code to itself, copy files, install gems and run workers.</p>

<p>If you want to restart the process, add machines or anything else, you can do it with the click of a button in the AWS UI.</p>

<h2>Comments? Questions?</h2>

<p>Please feel free</p>
]]></content>
  </entry>
  
</feed>
